{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trishabhanu/Code-Editor/blob/main/quickstarts/TwelveLabs_Quickstart_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYwIL79-xXQJ"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/twelvelabs-io/twelvelabs-developer-experience/blob/main/quickstarts/TwelveLabs_Quickstart_Embeddings.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in  Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmpYRcFNT30r"
      },
      "source": [
        "# Create embeddings\n",
        "\n",
        "This guide shows how to utilize the TwelveLabs Python SDK to create embeddings for your videos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMCAq7wYjx5N"
      },
      "source": [
        "# Prerequisites\n",
        "Before you begin, ensure the following prerequisites are met:\n",
        "\n",
        "- [Sign up](https://playground.twelvelabs.io/) for a free account and obtain your API key from the [API Key](https://playground.twelvelabs.io/dashboard/api-key) page. No credit card is required to use the Free plan. This plan allows you to index up to 600 minutes of videos, which is sufficient for a small project.\n",
        "- The videos you wish to upload must meet the requirements in the [Prerequisites](https://docs.twelvelabs.io/docs/create-video-embeddings#prerequisites) section of the **Create video embeddings** page.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sThd4J6Djx5N"
      },
      "source": [
        "# Procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndm_VcTAjx5O"
      },
      "source": [
        "## Install the TwelveLabs Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oCGrtnjjjx5P"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q twelvelabs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsG9DJG6jx5Q"
      },
      "source": [
        "## Configure your API key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8FjTXh_djx5Q"
      },
      "outputs": [],
      "source": [
        "# For Google Colab, store your API key as a Secret named `TL_API_KEY`. If you don't know how to create a Colab Secret, see https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75.\n",
        "\n",
        "from google.colab import userdata\n",
        "TL_API_KEY = userdata.get('TL_API_KEY')\n",
        "\n",
        "# For other Python environments, you can use environment variables\n",
        "# TL_API_KEY = os.environ.get('TL_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhXzSOCgUdmv"
      },
      "source": [
        "## **Generate Embeddings**\n",
        "Use the Embed API to create multimodal embeddings that are contextual vector representations for your videos and texts. Twelve Labs video embeddings capture all the subtle cues and interactions between different modalities, including the visual expressions, body language, spoken words, and the overall context of the video, encapsulating the essence of all these modalities and their interrelations over time.\n",
        "\n",
        "To create video embeddings, you must first upload your videos, and the platform must finish processing them. Uploading and processing videos require some time. Consequently, creating embeddings is an asynchronous process comprised of three steps:\n",
        "\n",
        "1. Upload and process a video: When you start uploading a video, the platform creates a video embedding task and returns its unique task identifier.\n",
        "\n",
        "2. Monitor the status of your video embedding task: Use the unique identifier of your task to check its status periodically until it's completed.\n",
        "\n",
        "3. Retrieve the embeddings: After the video embedding task is completed, retrieve the video embeddings by providing the task identifier.\n",
        "Learn more in the [docs](https://docs.twelvelabs.io/docs/create-video-embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elAj0cm1Upaa",
        "outputId": "84be8834-9dea-4031-8c31-cd057fed5e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created task: id=6826ce66a1ad1e4e3b23530f model_name=Marengo-retrieval-2.7 status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=processing\n",
            "  Status=ready\n",
            "Embedding done: ready\n",
            "  embedding_scope=clip embedding_option=visual-text start_offset_sec=0.0 end_offset_sec=6.0\n",
            "  embeddings: [0.0025792755, 0.014416745, 0.013344925, -0.023667203, -0.034136135]\n",
            "  embedding_scope=clip embedding_option=visual-text start_offset_sec=6.0 end_offset_sec=12.0\n",
            "  embeddings: [0.014718804, 0.0048405766, 0.021370944, -0.029890832, -0.02597869]\n",
            "  embedding_scope=clip embedding_option=audio start_offset_sec=0.0 end_offset_sec=6.0\n",
            "  embeddings: [-0.05493164, -0.010864258, -0.031982422, -0.05053711, -0.020263672]\n",
            "  embedding_scope=clip embedding_option=audio start_offset_sec=6.0 end_offset_sec=12.0\n",
            "  embeddings: [-0.050048828, -0.021118164, -0.016967773, -0.04296875, -0.019042969]\n"
          ]
        }
      ],
      "source": [
        "from twelvelabs import TwelveLabs\n",
        "from typing import List\n",
        "from twelvelabs.models.embed import EmbeddingsTask, SegmentEmbedding\n",
        "\n",
        "def print_segments(segments: List[SegmentEmbedding], max_elements: int = 5):\n",
        "    for segment in segments:\n",
        "        print(\n",
        "            f\"  embedding_scope={segment.embedding_scope} embedding_option={segment.embedding_option} start_offset_sec={segment.start_offset_sec} end_offset_sec={segment.end_offset_sec}\"\n",
        "        )\n",
        "        print(f\"  embeddings: {segment.embeddings_float[:max_elements]}\")\n",
        "\n",
        "client = TwelveLabs(api_key=TL_API_KEY)\n",
        "task = client.embed.task.create(\n",
        "    model_name=\"Marengo-retrieval-2.7\",\n",
        "    video_url=\"https://sample-videos.com/video321/mp4/720/big_buck_bunny_720p_2mb.mp4\" # # Example: https://sample-videos.com/video321/mp4/720/big_buck_bunny_720p_2mb.mp4\n",
        ")\n",
        "print(\n",
        "    f\"Created task: id={task.id} model_name={task.model_name} status={task.status}\"\n",
        ")\n",
        "\n",
        "def on_task_update(task: EmbeddingsTask):\n",
        "    print(f\"  Status={task.status}\")\n",
        "\n",
        "status = task.wait_for_done(\n",
        "    sleep_interval=2,\n",
        "    callback=on_task_update\n",
        ")\n",
        "print(f\"Embedding done: {status}\")\n",
        "\n",
        "task = task.retrieve(embedding_option=[\"visual-text\", \"audio\"])\n",
        "if task.video_embedding is not None and task.video_embedding.segments is not None:\n",
        "    print_segments(task.video_embedding.segments)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "3.10.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}